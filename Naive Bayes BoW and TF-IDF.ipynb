{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jTNV1_N6CayI"},"outputs":[],"source":["from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n","from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n","import pandas as pd\n","import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w7sDgY6XCayK"},"outputs":[],"source":["# import data\n","train_df = pd.read_csv('train_15_emoji.csv')\n","test_df = pd.read_csv('test_15_emoji.csv')\n","X_train = train_df['cleaned_content']\n","y_train = train_df['emoji_id']\n","X_test = test_df['cleaned_content']\n","y_test = test_df['emoji_id']\n","my_tags = list(train_df['emoji_id'].unique())\n","my_tags = [str(i) for i in my_tags]"]},{"cell_type":"markdown","metadata":{"id":"d_YDb8TECayL"},"source":["# Naive Bayes with tf-idf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_D_kSjBfCayM","outputId":"12bbb9b6-8326-4010-cc6a-37a6dea194ff"},"outputs":[{"data":{"text/plain":["Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n","                ('clf', MultinomialNB())])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# build model\n","nb = Pipeline([('vect', CountVectorizer()),\n","               ('tfidf', TfidfTransformer()),\n","               ('clf', MultinomialNB()),\n","              ])\n","\n","nb.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BFQ_c-ZyCayN","outputId":"6a03f955-7ed8-49bf-b305-ff9b00913043"},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy 0.3848743501511969\n","              precision    recall  f1-score   support\n","\n","           7       0.29      0.26      0.28      4462\n","           6       0.28      0.27      0.28      4386\n","           8       0.43      0.46      0.44      4466\n","          10       0.31      0.24      0.27      4501\n","           5       0.30      0.30      0.30      4513\n","           0       0.30      0.28      0.29      4514\n","           1       0.38      0.38      0.38      4504\n","           4       0.35      0.42      0.39      4458\n","          12       0.45      0.42      0.44      4370\n","          13       0.51      0.49      0.50      4426\n","           9       0.41      0.45      0.43      4468\n","           2       0.54      0.60      0.56      4508\n","           3       0.52      0.38      0.44      4532\n","          11       0.31      0.40      0.35      4452\n","          14       0.41      0.43      0.42      4571\n","\n","    accuracy                           0.38     67131\n","   macro avg       0.39      0.38      0.38     67131\n","weighted avg       0.39      0.38      0.38     67131\n","\n"]}],"source":["# model evaluation\n","y_pred = nb.predict(X_test)\n","print('accuracy %s' % accuracy_score(y_pred, y_test))\n","print(classification_report(y_test, y_pred,target_names=my_tags))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"585T8SZvCayN","outputId":"bd432112-fcb4-43b1-cf4e-4d5f918bbe9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 3 Prediction Accuracy: 0.627951319062728\n"]}],"source":["# Top 3 accuracy - overall score\n","def top_k_prediction(x, k):\n","    results = []\n","    prob = nb.predict_proba(x)\n","    for item in prob:\n","        # Create a copy of the original array to avoid modifying it\n","        arr_copy = item.copy()\n","\n","        # Get the indices that would sort the array in ascending order\n","        sorted_indices = np.argsort(arr_copy)\n","\n","        # Take the last 5 indices to get the indices of the top 5 elements\n","        top_indices = sorted_indices[-k:]\n","        \n","        results.append(top_indices)\n","        \n","    return results\n","\n","result = test_df.copy()\n","# get top 3 prediction \n","result[\"predict_emoji_3\"] = top_k_prediction(X_test, k = 3)\n","result[\"predict_accurate_3\"] = result.apply(lambda x: x.emoji_id in x.predict_emoji_3, axis = 1)\n","# Top 3 accuracy - overall score\n","print(\"Top 3 Prediction Accuracy:\", len(result[result[\"predict_accurate_3\"] == 1]) / len(result))"]},{"cell_type":"markdown","metadata":{"id":"gAgFcdWPCayO"},"source":["# Naive Bayes with BoW"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OwGlm3A_CayO"},"outputs":[],"source":["from collections import defaultdict\n","from nltk.corpus import stopwords\n","import random\n","import numpy as np\n","import math\n","\n","class DataReader:\n","    def __init__(self, tweet_file, labels_file):\n","        self.tweet_file = tweet_file\n","        self.labels_file = labels_file\n","        self.label_set = set()\n","        self.seed = random.seed(4222)\n","\n","\n","    def read_tweets(self):\n","        # with open(self.tweet_file, 'r') as doc:\n","        #     tweets = doc.read().splitlines()\n","        tweets = self.tweet_file\n","        random.seed(self.seed)\n","        random.shuffle(tweets)\n","        return tweets\n","\n","    def read_labels(self):\n","        # with open(self.labels_file, 'r') as doc:\n","        #     labels_for_tweets = doc.read().splitlines()\n","        labels_for_tweets = self.labels_file\n","        random.seed(self.seed)\n","        random.shuffle(labels_for_tweets)\n","        self.label_set = set(labels_for_tweets)\n","        return labels_for_tweets\n","\n","    def get_label_set(self):\n","        return self.label_set\n","\n","    @staticmethod\n","    def tokenize(tweet):\n","        stops = set(stopwords.words(\"english\"))\n","        bag_of_words = defaultdict(float)\n","        words = DataReader.extract_words_from_tweet(tweet)\n","        for word in words:\n","            if word[0] != \"#\" and word[0] != \"@\" and word not in stops:\n","                bag_of_words[word] += 1.0\n","        return bag_of_words\n","\n","    @staticmethod\n","    def extract_words_from_tweet(tweet):\n","        word_list = []\n","        word_string = \"\"\n","        for char in tweet:\n","            if char.isalpha():\n","                word_string = word_string + char\n","            elif not len(word_string) < 2:\n","                word_list.append(word_string.lower())\n","                word_string = \"\"\n","        return word_list\n","\n","    def get_features(self):\n","        tweets = self.read_tweets()\n","        labels = self.read_labels()\n","        np_labels = np.array(labels)\n","        vocab = set()\n","        for tweet in tweets:\n","            tokens = DataReader.tokenize(tweet).keys()\n","            for key in tokens:\n","                vocab.add(key)\n","        index_of_word = 0\n","        mapping = {}\n","        for word in vocab:\n","            mapping[word] = index_of_word\n","            index_of_word += 1\n","\n","        feature_vector = np.zeros((len(tweets), len(vocab)), dtype=np.uint8)\n","        counter = 0\n","        for tweet in tweets:\n","            tokens = DataReader.tokenize(tweet).keys()\n","            for key in tokens:\n","\n","                feature_vector[counter][mapping[key]] += 1\n","            counter += 1\n","        return feature_vector, np_labels\n","\n","    @staticmethod\n","    def get_tokens(bow):\n","        \"\"\"\n","        Returns the number of tokens in the bag of words.\n","        bow - bag of words representation\n","        \"\"\"\n","        sum_toks = 0.0\n","        for key in bow:\n","            sum_toks += bow[key]\n","        return sum_toks\n","\n","class NaiveBayes:\n","    def __init__(self, train_tweets, train_labels, test_tweets, test_labels, alpha=1):\n","        \n","        self.alpha = alpha\n","        self.vocabulary = set()\n","        self.total_tweets_per_class = defaultdict(float)\n","        self.word_counts_per_class = defaultdict(float)\n","\n","        self.words_per_class = {}\n","        self.train_tweets = list(train_tweets)\n","        self.train_labels = list(train_labels)\n","        self.test_tweets = list(test_tweets)\n","        self.test_labels = list(test_labels)\n","        self.label_set = set(train_labels)\n","        if len(set(train_labels)) != len(set(test_labels)):\n","            print(\"train:\", len(set(train_labels)), \"test:\", len(set(test_labels)))\n","            raise ValueError(\"Training and test labels are not the same\")\n","\n","        for label in self.label_set:\n","            self.words_per_class[label] = defaultdict(float)\n","\n","        self.prior_count_tweets = 0.0\n","\n","    def update_model(self):\n","        self.prior_count_tweets = len(self.train_tweets)\n","        for tweet_number in range(0, len(self.train_tweets)):\n","            label = self.train_labels[tweet_number]\n","            self.total_tweets_per_class[label] += 1.0\n","            bow = DataReader.tokenize(self.train_tweets[tweet_number])\n","            sum = DataReader.get_tokens(bow)\n","            self.word_counts_per_class[label] += sum\n","            for key in bow:\n","                self.words_per_class[label][key] += bow[key]\n","                self.vocabulary.add(key)\n","        \n","\n","    def p_word_given_label_and_pseudocount(self, word, label):\n","        \"\"\"\n","        Returns the probability of word given label wrt psuedo counts.\n","        alpha - pseudocount parameter\n","        \"\"\"\n","        den = self.alpha * len(self.vocabulary)\n","        my_word_prob = self.words_per_class[label][word] + self.alpha\n","        total_words_label = self.word_counts_per_class[label] + den\n","        return my_word_prob / total_words_label\n","\n","    def log_likelihood(self, bow, label):\n","        \"\"\"\n","        Computes the log likelihood of a set of words give a label and pseudocount.\n","        bow - a bag of words (i.e., a tokenized document)\n","        label - either the positive or negative label\n","        alpha - float; pseudocount parameter\n","    \n","        \"\"\"\n","        log_lk = 0\n","        for key in bow.keys():\n","            log_lk += math.log(self.p_word_given_label_and_pseudocount(key, label))\n","        return log_lk\n","\n","    def log_prior(self, label):\n","        \"\"\"\n","        Returns the log prior of a document having the class 'label'.\n","        \"\"\"\n","        c = self.total_tweets_per_class[label]\n","        tot = self.prior_count_tweets\n","        # do add one smoothing\n","        c += 1 \n","        tot += len(self.vocabulary)\n","            \n","        return math.log(c / tot)\n","\n","    def unnormalized_log_posterior(self, bow, label):\n","        \"\"\"\n","        Computes the unnormalized log posterior (of doc being of class 'label').\n","        bow - a bag of words (i.e., a tokenized document)\n","        \"\"\"\n","        return self.log_prior(label) + self.log_likelihood(bow, label)\n","\n","    def classify(self, bow):\n","        \"\"\"\n","        Classifies a tweet based on it's bag of word representation\n","        bow - a bag of words (i.e., a tokenized document)\n","        alpha - pseudocount\n","        \"\"\"\n","        max_unnormalized = float('-inf')\n","        argmax_unnormalized = '-1'\n","        for label in self.label_set:\n","            var_ret = self.unnormalized_log_posterior(bow, label)\n","            if var_ret > max_unnormalized:\n","                max_unnormalized = var_ret\n","                argmax_unnormalized = label\n","        return argmax_unnormalized\n","    \n","    def get_top_k_lables(self, bow, k):\n","        \"\"\"\n","        Classifies a tweet based on it's bag of word representation\n","        bow - a bag of words (i.e., a tokenized document)\n","        alpha - pseudocount\n","        \"\"\"\n","        var_ret_ls = []\n","        var_ls = []\n","        \n","        for label in self.label_set:\n","            var_ls.append(label)\n","            var_ret_ls.append(self.unnormalized_log_posterior(bow, label))\n","        var_ret_ls, var_ls = zip(*sorted(zip(var_ret_ls, var_ls), reverse=True))\n","        # return the top k labels\n","        return var_ls[:k]\n","    \n","    def evaluate_classifier_accuracy_top_k(self, k):\n","    \n","        def compute_accuracy(tweets, labels):\n","\n","            # inialize the dictionary\n","            pred_accuracy_dict = {}\n","            for label in self.label_set:\n","                pred_accuracy_dict[label] = {\"correct\": 0.0, \"total\": 0.0, \"tested_tweets\":[]} # tested_tweets is for tweets with multiple emojis\n","\n","            l = len(tweets)\n","            for l in range(l):\n","                label = labels[l]\n","                tweet = tweets[l]\n","                if tweet in pred_accuracy_dict[label][\"tested_tweets\"]:\n","                    continue\n","                else:\n","                    bow = DataReader.tokenize(tweet)\n","                    predicted_label = self.get_top_k_lables(bow, k)\n","                    if label in predicted_label:\n","                        pred_accuracy_dict[label][\"correct\"] += 1.0\n","                    pred_accuracy_dict[label][\"total\"] += 1.0\n","                    pred_accuracy_dict[label][\"tested_tweets\"].append(tweet)\n","        \n","            # calculate the accuracy for each label\n","            for label in self.label_set:\n","                if pred_accuracy_dict[label][\"total\"] == 0:\n","                    pred_accuracy_dict[label][\"accuracy\"] = 0.0\n","                else:\n","                    pred_accuracy_dict[label][\"accuracy\"] = round(pred_accuracy_dict[label][\"correct\"] / pred_accuracy_dict[label][\"total\"],2)*100\n","            \n","            res = {} #remove the total and correct\n","            for key in pred_accuracy_dict:\n","                res[key] = pred_accuracy_dict[key][\"accuracy\"]\n","\n","            return res # in percentage\n","        \n","        # train accuracy\n","        train_acc = compute_accuracy(self.train_tweets, self.train_labels)\n","        # test accuracy\n","        test_acc = compute_accuracy(self.test_tweets, self.test_labels)\n","\n","        # accuracy df \n","        # initialize list elements\n","        emoji_id= list(train_acc.keys())\n","        \n","        # Create the pandas DataFrame with column name is provided explicitly\n","        acc_df = pd.DataFrame(emoji_id, columns=['emoji_id'])\n","        acc_df['train_accuracy'] = acc_df['emoji_id'].map(train_acc)\n","        acc_df['test_accuracy'] = acc_df['emoji_id'].map(test_acc)\n","\n","        \n","        return acc_df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCdHgvaFCayQ"},"outputs":[],"source":["\n","train_tweets = train_df[\"cleaned_content\"]\n","train_labels = train_df[\"emoji_id\"]\n","test_tweets = test_df[\"cleaned_content\"]\n","test_labels = test_df[\"emoji_id\"]\n","\n","# generate bow for each tweet in the train and test set\n","train_df[\"bow\"]  = train_df[\"cleaned_content\"].apply(lambda x: DataReader.tokenize(x))\n","test_df[\"bow\"]  = test_df[\"cleaned_content\"].apply(lambda x: DataReader.tokenize(x))\n","\n","nb_obj = NaiveBayes(train_tweets, train_labels, test_tweets, test_labels)\n","nb_obj.update_model()\n","train_df[\"pred\"] = train_df[\"bow\"].apply(lambda x: nb_obj.get_top_k_lables(x,1)[0])\n","test_df[\"pred\"] = test_df[\"bow\"].apply(lambda x: nb_obj.get_top_k_lables(x,1)[0])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIisvlg-CayR","outputId":"88dac0a7-4354-4f71-ddff-94a0bc80b0b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy 0.33111379243568545\n","              precision    recall  f1-score   support\n","\n","           7       0.26      0.20      0.23      4462\n","           6       0.16      0.30      0.20      4386\n","           8       0.38      0.40      0.39      4466\n","          10       0.30      0.19      0.23      4501\n","           5       0.26      0.23      0.24      4513\n","           0       0.27      0.27      0.27      4514\n","           1       0.35      0.33      0.34      4504\n","           4       0.33      0.37      0.35      4458\n","          12       0.44      0.37      0.40      4370\n","          13       0.47      0.41      0.44      4426\n","           9       0.35      0.40      0.37      4468\n","           2       0.49      0.47      0.48      4508\n","           3       0.43      0.33      0.37      4532\n","          11       0.30      0.33      0.31      4452\n","          14       0.38      0.38      0.38      4571\n","\n","    accuracy                           0.33     67131\n","   macro avg       0.34      0.33      0.33     67131\n","weighted avg       0.34      0.33      0.33     67131\n","\n"]}],"source":["\n","# classification report\n","from sklearn.metrics import classification_report\n","# model accuracy, precision and F1:\n","y_true = test_df[\"emoji_id\"]\n","y_pred = test_df[\"pred\"]\n","\n","print('accuracy %s' % accuracy_score(y_pred, y_true))\n","print(classification_report(y_true, y_pred,target_names=my_tags))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T9rkgxWECayR","outputId":"cc4a8a74-2ac0-401d-d11b-7f8ed9737211"},"outputs":[{"name":"stdout","output_type":"stream","text":["top 3 Accuracy:\n","    emoji_id  train_accuracy  test_accuracy\n","10        10            73.0           61.0\n","11        11            68.0           60.0\n","9          9            70.0           58.0\n","13        13            69.0           57.0\n","14        14            70.0           57.0\n","2          2            68.0           56.0\n","1          1            69.0           54.0\n","5          5            69.0           54.0\n","7          7            64.0           51.0\n","0          0            67.0           50.0\n","4          4            66.0           50.0\n","8          8            65.0           49.0\n","3          3            64.0           48.0\n","6          6            63.0           48.0\n","12        12            49.0           39.0\n","Average Top 3 Accuracy is 52.8\n"]}],"source":["# top k \n","acc_df = nb_obj.evaluate_classifier_accuracy_top_k(3)\n","acc_df = acc_df.sort_values(by=['test_accuracy'], ascending=False)\n","print( \"top 3 Accuracy:\")\n","print(acc_df)\n","print(\"Average Top 3 Accuracy is\", round(acc_df[\"test_accuracy\"].mean(),2))"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}